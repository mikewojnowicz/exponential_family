Let $p(y \cond \param)$ be an exponential family likelihood, and let $p(\param)$ be its conjugate prior. 

We can write the prior as 
\begin{align*}
p(\param ) &= \exp \biggset{\biggip{\naturalParam_\param^o}{\sufficientStatsFunction_\param (\param)} - \log Z_\param(\naturalParam_\param^o)} 
%&\propto \exp \biggset{\biggip{\naturalParam_\param^o, \sufficientStatsFunction_\param (\param)}}
\end{align*}

And the likelihood for a single observation $y_i$ as 
\begin{align*}
p(y_i \cond \param)  & \stackrel{1}{=} \exp \biggset{ \biggip{\naturalParam_y(\param)}{\sufficientStatsFunction_y(y_i)} - \log Z_y (\naturalParam_y(\param)) } \\
& \stackrel{2}{=} \exp \biggset{ \biggip{ \bigparenth{\naturalParam_y(\param), \; - \log Z_y (\naturalParam_y(\param))}}{\bigparenth{\sufficientStatsFunction_y(y_i), \; 1}}  } \\
& \stackrel{3}{=} \exp \biggset{ \biggip{\sufficientStatsFunction_\param(\param)}{\bigparenth{\sufficientStatsFunction_y(y_i),1}}}   
\end{align*}
where (1) is true by the exponential family assumption, (2) regroups terms to make conjugacy clearer and (3) must be true given conjugacy. 


By Bayes law, the posterior after a single observation $y_i$ is given by
\begin{align*}
p(\param \cond y_i)  &\propto p(\param, y_i) \\
	&=\exp \biggset{ \biggip{ \naturalParam_\param(y_i)}{\sufficientStatsFunction_\param(\param) } - \log Z_\param(\naturalParam_\param^o)} 
\end{align*}
where $\naturalParam_\param(y_i) = \naturalParam_\param^o + \bigparenth{\sufficientStatsFunction_y(y_i),1}$, i.e. the posterior natural parameter is the sum of the prior natural parameter and the sufficient statistics concatenated with the number of samples. 

And so after re-normalizing
\begin{align*}
p(\param \cond y_i)  = \exp \biggset{ \biggip{ \naturalParam_\param(y_i)}{\sufficientStatsFunction_\param(\param) } - \log Z_\param \big(\naturalParam_\param(y_i)\big)}
\labelit \label{eqn:posterior_for_exponential_family_after_one_obs} 
\end{align*}
  
After seeing multiple i.i.d observations $y=(y_1,...,y_n)$ from the likelihood, the posterior is given by
\begin{align*}
p(\param \cond y)  = \exp \biggset{ \biggip{\naturalParam_\param(y)}{\sufficientStatsFunction_\param(\param) } - \log Z_\param \big(\naturalParam_\param(y)\big)} 
\labelit \label{eqn:posterior_for_exponential_family_after_many_obs} 
\end{align*}
where $\naturalParam_\param(y) = \naturalParam_\param^o + \bigparenth{ \sum_{i=1}^n \sufficientStatsFunction_y(y_i),n}$.

This motivates interpreting the prior parameter as $\naturalParam_\param = (\tau_0, n_0)$, where $\tau_0 \in \R^{\dim(\naturalParam_\param) - 1}$ is interpreted as sufficient statistics and $n_0 \in \R$ is interpreted as a the sample size of a prior psuedo-dataset. 
