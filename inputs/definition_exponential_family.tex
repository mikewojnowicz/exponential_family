\begin{definition}
We can define an \textit{exponential family} as a set of probability distributions, indexed by natural parameter $\eta \in \naturalParamSpace$,%\redfootnote{TODO: Add restriction on parameter space so that the density is normalizable}  
 whose probability density functions with respect to measure $\mu$ on $\X$ have the following form
\begin{align}
 p_\eta(x) = \carrierDensity(x) \exp \{ \eta^\top \sufficientStatsFunction(x) - \logNormalizerFunction(\eta)\} 
\label{eqn:exponential_family_natural}
 \end{align}
where $\sufficientStatsFunction  : \X \to \R^p$ is the \textit{sufficient statistics function}, $\carrierDensity : \X \to \R$ is the \textit{carrier density}, $\eta \in \naturalParamSpace \subset \R^p$ is the \textit{natural parameter},  and $\logNormalizerFunction : \naturalParamSpace \to \R$ is a strictly convex and $C^{\infty}$ differentiable real-valued function known as the \textit{log normalizer} or \textit{log partition function};  that is $\logNormalizerFunction(\eta) = \log Z(\eta)$ where 
\begin{equation}
\label{eqn:partition_function}
 Z(\eta) := \ds\int  \carrierDensity(x) \exp \{ \eta^\top \sufficientStatsFunction(x)  \} \; \mu(dx)	
\end{equation}
%and so $a$ is determined by the other components of density. 
%TODO add in interpetation as \textit{cumulative generating function};


We refer to $\mu$ as the \textit{base measure}.\footnote{Some presentations use the term ``base measure" to refer to $\carrierDensity(x)$, but that is an abuse of notation, as $\carrierDensity$ is not a measure.}  Typically $\mu$ is the Lesbesgue measure or counting measure.  If $\mu$ is the Lesbesgue measure, then the density $p_\eta$ is a probability density function.  If $\mu$ is the counting measure, then the density $p_\eta$ is a probability mass function.\footnote{If measure theory is off-putting, just take $\mu$ to be the Lesbesgue measure for continuous random variables, in which case one can remove it from the equation, and simply write $Z(\eta) := \ds\int  \carrierDensity(x) \exp \{ \eta^\top \sufficientStatsFunction (x)  \} \; dx $, and take $\mu$ to be the counting measure for discrete random variables, in which case one can write $Z(\eta) := \ds\sum_{x \in \X} \carrierDensity(x) \exp \{ \eta^\top \sufficientStatsFunction(x)  \} $. Indeed, we will make precisely these assumptions throughout the document, unless otherwise noted. }  %\footnote{Some presentations assume Lebesgue measure on $\X$, and write \eqref{eqn:partition_function} more simply as $Z(\eta) := \ds\int  \carrierDensity(x) \exp \{ \eta^\top \sufficientStatsFunction(x)  \} \; dx $.  In contrast, presentations which allow for general measures $\mu$ (e.g. \cite{johnson2016composing}, or this one)  can simply absorb $\carrierDensity(x)$ into the measure $\mu$ and write \eqref{eqn:partition_function} as $Z(\eta) := \ds\int  \exp \{ \eta^\top \sufficientStatsFunction(x)  \} \; \mu (dx) $.  In the former case, the term \textit{carrier density} refers to $\carrierDensity(x)$ -- although this is an abuse of notation.  We use the term \textit{base measure} refers to $\mu$. Some presentations use the term ``base measure" to refer to $\carrierDensity(x)$, but that is an abuse of notation, as $\carrierDensity$ is not a measure.}  
%\redfootnote{TODO: Align more closely with Jordan, who uses integration against probability measure here.  He remarks on this somewhere in his exponential family lecture notes.   What also may be helpful is this beautiful excerpt from pp.38 of \cite{wainwright2008graphical}: `` $[...]$ we represent the probability distribution as a density $p$ absolutely continuous with respect to some measure $\eta$.   This base measure $\eta$ might be the counting measure on $\set{0, 1, ..., r-1}$,  in which case $p$ is a probability mass function; alternatively, for a continuous random vector, the base measure $\eta$ could be the ordinary Lebesgue measure on $\R$."}  
\label{def:exponential_family}
\end{definition} 
